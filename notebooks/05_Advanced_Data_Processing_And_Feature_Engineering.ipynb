{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5193d358-340e-41b7-a643-d5a5e6da0a95",
   "metadata": {},
   "source": [
    "<center><h1><font size=6> Initial Data Processing and Feature Engineering </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd840d7b-bf68-4dab-b547-1c747a87c416",
   "metadata": {},
   "source": [
    "### Load libraries and setup notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7911109-a7f0-48e7-9d2b-22927be84dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# set pandas configurations\n",
    "pd.set_option(\"display.precision\", 2) # display to 1 decimpal place\n",
    "pd.set_option(\"display.max.columns\", None) # display all columns so we can view the whole dataset\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) # Disable scientific notation for pandas\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning) # Disable setting with copy warnings\n",
    "\n",
    "\n",
    "# set directories\n",
    "os.chdir('..') # change current working directory to the parent directory to help access files/directories at a higher level\n",
    "DATAPATH = Path(r'data') # set data path\n",
    "\n",
    "\n",
    "# import from source directory\n",
    "from src import constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f131d6a-4fe5-412a-8e1d-e2f45cce03f7",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a974e7d-5798-4f6a-aeb7-feb4100a1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.read_csv(f\"{DATAPATH}/processed/X_train_full.csv\")\n",
    "y_train_full = pd.read_csv(f\"{DATAPATH}/processed/y_train_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746e794f-a93d-4ffc-bd33-d72c15fb9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train_full.copy().set_index('unique_match_id', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dc718-7e03-487c-ab7d-40cc3bb8c51e",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970c2527-2422-42b4-bf8c-d585e95e6919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Total Missing Values  Missing Percentage\n",
      "season                                                 0                0.00\n",
      "round                                                  0                0.00\n",
      "day                                                    0                0.00\n",
      "team                                                   0                0.00\n",
      "promoted                                               0                0.00\n",
      "opponent                                               0                0.00\n",
      "promoted_opponent                                      0                0.00\n",
      "home                                                   0                0.00\n",
      "days_since_last_game                                 434                2.43\n",
      "games_played_last_21_days                            465                2.60\n",
      "pl_total_points                                        4                0.02\n",
      "pl_total_gf                                            4                0.02\n",
      "pl_total_ga                                            4                0.02\n",
      "pl_total_goal_diff                                     4                0.02\n",
      "pl_position                                            0                0.00\n",
      "last_h2h                                            1054                5.89\n",
      "last_h2h_form                                       1054                5.89\n",
      "last_h2h_venue                                      2106               11.77\n",
      "last_h2h_venue_form                                 2106               11.77\n",
      "prev_season_points                                  2621               14.65\n",
      "prev_season_gf                                      2621               14.65\n",
      "prev_season_ga                                      2621               14.65\n",
      "prev_season_goal_diff                               2621               14.65\n",
      "points_pl_form                                        23                0.13\n",
      "gf_pl_form                                            23                0.13\n",
      "ga_pl_form                                            23                0.13\n",
      "days_since_last_game_opponent                        432                2.41\n",
      "games_played_last_21_days_opponent                   462                2.58\n",
      "pl_total_points_opponent                               6                0.03\n",
      "pl_total_gf_opponent                                   6                0.03\n",
      "pl_total_ga_opponent                                   6                0.03\n",
      "pl_total_goal_diff_opponent                            6                0.03\n",
      "pl_position_opponent                                   0                0.00\n",
      "points_pl_form_opponent                               25                0.14\n",
      "gf_pl_form_opponent                                   25                0.14\n",
      "ga_pl_form_opponent                                   25                0.14\n",
      "prev_season_points_opponent                         2620               14.65\n",
      "prev_season_gf_opponent                             2620               14.65\n",
      "prev_season_ga_opponent                             2620               14.65\n",
      "prev_season_goal_diff_opponent                      2620               14.65\n"
     ]
    }
   ],
   "source": [
    "# define function to summarise missing values\n",
    "def missing_values_summary(df):\n",
    "    missing_values = df.isnull().sum()  # Calculate total missing values per column\n",
    "    total_values = df.shape[0]  # Total number of rows in the DataFrame\n",
    "    missing_percentage = (missing_values / total_values) * 100  # Calculate percentage of missing values\n",
    "\n",
    "    summary_df = pd.DataFrame({'Total Missing Values': missing_values, 'Missing Percentage': missing_percentage})\n",
    "    return summary_df\n",
    "\n",
    "# summarise missing values for data frame\n",
    "summary = missing_values_summary(train)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09553fb0-7e6d-4152-8c97-e965140401c9",
   "metadata": {},
   "source": [
    "#### Define a set of custom transformers inhereted from scikit-learn base classes to transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0167f49-ad88-4fea-8e55-cb0c55528769",
   "metadata": {},
   "source": [
    "For some columns, we only have a small amount of irregular missing values. Here, it makes sense to just remove the rows associated with these observations from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b44db33-ce43-4855-becf-1633a54470a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom transformer to remove any rows that have NA values for \n",
    "class DropNaRowsTransformer(BaseEstimator, TransformerMixin):\n",
    "    # initalise additional parameters based on the chosen columns\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.dropna(subset=self.columns, inplace=False)\n",
    "        return X_transformed\n",
    "    \n",
    "# define list of columns to remove NAs\n",
    "columns_to_remove_nas = ['season', 'day', 'round',  'team', 'home', 'promoted', 'opponent', 'promoted_opponent', 'pl_position', 'pl_position_opponent',\n",
    "                        'pl_total_points', 'pl_total_gf', 'pl_total_ga', 'pl_total_goal_diff', 'pl_total_points_opponent', 'pl_total_gf_opponent', 'pl_total_ga_opponent', 'pl_total_goal_diff_opponent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8840e-8472-4679-a6c0-9aa578c8b7f3",
   "metadata": {},
   "source": [
    "For other columns, it makes sense to impute the missing values with the averages of the values. An example of this is the days since last game and number of games in last 21 days feature. From the EDA, we saw that the missing values for these features tend to all be in the first game week due to the lack of data. It therefore makes sense to just impute them as the average over the course of the season. This means all teams/opponents will have the same value in the first gameweek which makes sense intuitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05026448-59ab-4d01-8115-8a08df116481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom transformer to impute missing values with the mean of each column\n",
    "class MeanImputer(BaseEstimator, TransformerMixin):\n",
    "    # initalise additional parameters based on the chosen columns\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.means = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            self.means[column] = {\n",
    "                'mean': X[column].mean()\n",
    "            }\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for column in self.columns:\n",
    "            X_transformed[column] = X_transformed[column].fillna(value=self.means[column]['mean'])\n",
    "        return X_transformed\n",
    "    \n",
    "    \n",
    "# define list of columns to be imputed using the mean imputer\n",
    "columns_to_impute_with_mean = ['days_since_last_game', 'games_played_last_21_days', 'days_since_last_game_opponent', 'games_played_last_21_days_opponent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6002ab-0153-4410-a6fb-6f8775e3e7c7",
   "metadata": {},
   "source": [
    "For some variables, whether there is a missing value or not is highly linked to the team's promotion status. This is because promoted teams dont appear in the previous season's data so we can't calculate some metrics. For these cases, it makes sense to impute the missing values based on the average historic values of promoted or non-promoted teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd813785-d366-4525-8c00-d90c6d490177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom transformer for imputing missing values based on the promotion status - if the team is promoted, replace NA the 10th percentile value or the 50th percentile if not\n",
    "class PromotedImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, columns_opponent):\n",
    "        self.columns = columns\n",
    "        self.columns_opponent = columns_opponent\n",
    "        self.percentiles = {}\n",
    "        self.percentiles_opponent = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            self.percentiles[column] = {\n",
    "                '10th': X[column].quantile(0.1),\n",
    "                '50th': X[column].quantile(0.5)\n",
    "            }\n",
    "        for column_opponent in self.columns_opponent:\n",
    "            self.percentiles_opponent[column_opponent] = {\n",
    "                '10th': X[column_opponent].quantile(0.1),\n",
    "                '50th': X[column_opponent].quantile(0.5)\n",
    "            }\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for column in self.columns:\n",
    "            X_transformed.loc[X_transformed['promoted'] == 1, column] = X_transformed.loc[X_transformed['promoted'] == 1, column].fillna(value=self.percentiles[column]['10th'])\n",
    "            X_transformed.loc[X_transformed['promoted'] == 0, column] = X_transformed.loc[X_transformed['promoted'] == 0, column].fillna(value=self.percentiles[column]['50th'])\n",
    "        for column_opponent in self.columns_opponent:\n",
    "            X_transformed.loc[X_transformed['promoted_opponent'] == 1, column_opponent] = X_transformed.loc[X_transformed['promoted_opponent'] == 1, column_opponent].fillna(value=self.percentiles_opponent[column_opponent]['10th'])\n",
    "            X_transformed.loc[X_transformed['promoted_opponent'] == 0, column_opponent] = X_transformed.loc[X_transformed['promoted_opponent'] == 0, column_opponent].fillna(value=self.percentiles_opponent[column_opponent]['50th'])\n",
    "        return X_transformed\n",
    "    \n",
    "    \n",
    "# define list of columns to impute in this way\n",
    "columns_to_impute_based_on_promotion_status = ['prev_season_points', 'prev_season_gf', 'prev_season_ga', 'prev_season_goal_diff', 'points_pl_form', 'gf_pl_form', 'ga_pl_form']\n",
    "columns_to_impute_based_on_promotion_status_oppontent = ['prev_season_points_opponent', 'prev_season_gf_opponent', 'prev_season_ga_opponent', 'prev_season_goal_diff_opponent', 'points_pl_form_opponent', 'gf_pl_form_opponent', 'ga_pl_form_opponent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a3450-f7b1-4b80-ab91-f53b4bb8bd20",
   "metadata": {},
   "source": [
    "For some other columns, we might want to impute the missing values in a more sophisticated way. For example, the teams' and opponents' H2H record is found to have a high correlation with the predictor (see EDA) and so could be an important determinant in our model. However, where two teams havent played each other before, we won't have this metric. I want to impute the missing values here using a clustering algorithm based on important determinants of game results, namely the venue of the match and the team and opponents' points acheived in previous seasons. This will impute the head to head records based on a metric of how good the team and opponent is, as well as the venue identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2ea008-2f7d-4ba3-a295-73cd6276cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom transformer to impute missing values based on a decision tree algorithm trained on the relationship between venue and team metrics for the non-missing value data we have\n",
    "class DecisionTreeClassifierImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_columns, reference_columns):\n",
    "        self.target_columns = target_columns\n",
    "        self.reference_columns = reference_columns\n",
    "        self.decision_tree_classifiers = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Fit a separate Decision Tree model for each target column\n",
    "        for target_column in self.target_columns:\n",
    "    \n",
    "            # Split out X and y for decision tree: the X will be the reference columns and the data where the target column is not NA\n",
    "            X_where_target_non_na = X[X[target_column].notna()]\n",
    "            X_decision_tree = X_where_target_non_na[self.reference_columns]\n",
    "            y_decision_tree = X_where_target_non_na[target_column]\n",
    "\n",
    "            # Create an instance of the Decision Tree regressor\n",
    "            decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "            # Fit the model on the reference columns and target variable\n",
    "            decision_tree.fit(X_decision_tree, y_decision_tree)\n",
    "\n",
    "            # assign decision tree model to column\n",
    "            self.decision_tree_classifiers[target_column] = decision_tree\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Apply Decision Tree model to target columns\n",
    "        for target_column in self.target_columns:\n",
    "    \n",
    "            # Split out the X where these is a missing value in the target column for prediction\n",
    "            X_where_target_is_na = X[X[target_column].isna()]\n",
    "            X_decision_tree_predict = X_where_target_is_na[self.reference_columns]\n",
    "\n",
    "            # collect classifier for specific variable\n",
    "            decision_tree = self.decision_tree_classifiers[target_column]\n",
    "\n",
    "            # use decision tree to predict target column\n",
    "            y_decision_tree_predicted = decision_tree.predict(X_decision_tree_predict)\n",
    "\n",
    "            # Replace the missing values in the target column with the predicted values\n",
    "            X_transformed.loc[X_where_target_is_na.index, target_column] = y_decision_tree_predicted\n",
    "        \n",
    "        return X_transformed\n",
    "\n",
    "# define a list of columns to be imputed in this way alongside the columns to use as reference columns\n",
    "columns_to_impute_based_on_decision_tree = ['last_h2h', 'last_h2h_form', 'last_h2h_venue', 'last_h2h_venue_form']\n",
    "reference_columns_for_decision_tree = ['home', 'prev_season_points', 'prev_season_points_opponent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca02b4-a2f7-408c-af38-03076e88ebe2",
   "metadata": {},
   "source": [
    "#### Transform data using transformation pipeline based on pre-defined custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c61850e-c1b8-4048-a2ac-85b847c019d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_transformation_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"remove_rows_with_nas\", DropNaRowsTransformer(columns=columns_to_remove_nas)),\n",
    "        (\"impute_with_means_of_columns\", MeanImputer(columns=columns_to_impute_with_mean)),\n",
    "        (\"impute_with_mean_of_columns_by_promotion_status\", PromotedImputer(columns=columns_to_impute_based_on_promotion_status,\n",
    "                                                                           columns_opponent=columns_to_impute_based_on_promotion_status_oppontent)),\n",
    "        (\"impute_based_on_decision_tree_algorithm\", DecisionTreeClassifierImputer(target_columns=columns_to_impute_based_on_decision_tree,\n",
    "                                                                                  reference_columns=reference_columns_for_decision_tree))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d781e04-6600-4d07-90bd-b0bf86d0f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Total Missing Values  Missing Percentage\n",
      "season                                                 0                0.00\n",
      "round                                                  0                0.00\n",
      "day                                                    0                0.00\n",
      "team                                                   0                0.00\n",
      "promoted                                               0                0.00\n",
      "opponent                                               0                0.00\n",
      "promoted_opponent                                      0                0.00\n",
      "home                                                   0                0.00\n",
      "days_since_last_game                                   0                0.00\n",
      "games_played_last_21_days                              0                0.00\n",
      "pl_total_points                                        0                0.00\n",
      "pl_total_gf                                            0                0.00\n",
      "pl_total_ga                                            0                0.00\n",
      "pl_total_goal_diff                                     0                0.00\n",
      "pl_position                                            0                0.00\n",
      "last_h2h                                               0                0.00\n",
      "last_h2h_form                                          0                0.00\n",
      "last_h2h_venue                                         0                0.00\n",
      "last_h2h_venue_form                                    0                0.00\n",
      "prev_season_points                                     0                0.00\n",
      "prev_season_gf                                         0                0.00\n",
      "prev_season_ga                                         0                0.00\n",
      "prev_season_goal_diff                                  0                0.00\n",
      "points_pl_form                                         0                0.00\n",
      "gf_pl_form                                             0                0.00\n",
      "ga_pl_form                                             0                0.00\n",
      "days_since_last_game_opponent                          0                0.00\n",
      "games_played_last_21_days_opponent                     0                0.00\n",
      "pl_total_points_opponent                               0                0.00\n",
      "pl_total_gf_opponent                                   0                0.00\n",
      "pl_total_ga_opponent                                   0                0.00\n",
      "pl_total_goal_diff_opponent                            0                0.00\n",
      "pl_position_opponent                                   0                0.00\n",
      "points_pl_form_opponent                                0                0.00\n",
      "gf_pl_form_opponent                                    0                0.00\n",
      "ga_pl_form_opponent                                    0                0.00\n",
      "prev_season_points_opponent                            0                0.00\n",
      "prev_season_gf_opponent                                0                0.00\n",
      "prev_season_ga_opponent                                0                0.00\n",
      "prev_season_goal_diff_opponent                         0                0.00\n"
     ]
    }
   ],
   "source": [
    "transformed_training_data = missing_value_transformation_pipe.fit_transform(train)\n",
    "summary = missing_values_summary(transformed_training_data)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eab114-62a7-4c34-86bb-d7c8de629b32",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29ed45-66e6-4eb5-aa75-0cd509be42f2",
   "metadata": {},
   "source": [
    "I want to scale my numeric features using the standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d23759e-a554-4796-b14e-29e5b401f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categogrical variables not for scaling\n",
    "categorical_columns = ['season', 'round', 'day', 'promoted', 'promoted_opponent', 'home']\n",
    "\n",
    "# Store the index of transformed_training_data\n",
    "index = transformed_training_data.index\n",
    "\n",
    "# Select only numeric columns for scaling - ignore ID and any categorical variables like season, round and venue\n",
    "scaling_columns = transformed_training_data.drop(columns=categorical_columns, inplace=False).select_dtypes(include='number').columns\n",
    "\n",
    "# Subset the transformed_train DataFrame with numeric columns\n",
    "scaling_data = transformed_training_data[scaling_columns]\n",
    "\n",
    "# Scale the numeric data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(scaling_data)\n",
    "\n",
    "# Create a DataFrame from the scaled numeric data\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=scaling_columns)\n",
    "\n",
    "# Set the index of scaled_data to the stored index\n",
    "scaled_data.index = index\n",
    "\n",
    "# combine back with categorical columns\n",
    "scaled_training_data = pd.concat([transformed_training_data[categorical_columns], scaled_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2a148a-1f35-4ebc-89aa-958977d53a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write generic function to scale numeric data\n",
    "def scale_numeric_data(data, categorical_columns):\n",
    "    # Store the index of the input DataFrame\n",
    "    index = data.index\n",
    "\n",
    "    # Select only numeric columns for scaling\n",
    "    scaling_columns = data.drop(columns=categorical_columns, inplace=False).select_dtypes(include='number').columns\n",
    "\n",
    "    # Subset the DataFrame with numeric columns\n",
    "    scaling_data = data[scaling_columns]\n",
    "\n",
    "    # Scale the numeric data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(scaling_data)\n",
    "\n",
    "    # Create a DataFrame from the scaled numeric data\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=scaling_columns)\n",
    "\n",
    "    # Set the index of the scaled data to the stored index\n",
    "    scaled_data.index = index\n",
    "\n",
    "    # Combine the scaled numeric data with the categorical columns\n",
    "    scaled_data = pd.concat([data[categorical_columns], scaled_data], axis=1)\n",
    "\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b07051-5892-47e0-8982-db5ad3864a4c",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1cadf-cd24-4773-8dbb-2637acb6e91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8186f625-607e-40c7-98ad-56dd4e9aa95a",
   "metadata": {},
   "source": [
    "### Process target variable for training data and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee250b97-eb17-486f-8f5e-a2cdded81089",
   "metadata": {},
   "source": [
    "#### Training Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9293901f-6e5d-4593-ae78-a4bf3d2d4be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucel\\Downloads\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# collect training target data\n",
    "train_y = y_train_full.copy().set_index('unique_match_id', inplace=False)\n",
    "\n",
    "# encode target variable (0, 1, 2)\n",
    "encoder = LabelEncoder()\n",
    "train_y_encoded = encoder.fit_transform(train_y)\n",
    "\n",
    "# Create a DataFrame with the encoded target variable and assign the index\n",
    "train_y_encoded = pd.DataFrame(train_y_encoded, index=train_y.index, columns=['target'])\n",
    "\n",
    "# keep only the index columns that are in the processed train X\n",
    "scaled_train_y = train_y_encoded[train_y_encoded.index.isin(scaled_training_data.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a3b9e-1dd7-46b5-bafb-f9564557b229",
   "metadata": {},
   "source": [
    "#### Test X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610ff311-0e68-406b-ab4b-42fb375d2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect testing data\n",
    "X_test_full = pd.read_csv(f\"{DATAPATH}/processed/X_test_full.csv\")\n",
    "y_test_full = pd.read_csv(f\"{DATAPATH}/processed/y_test_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039bfc73-98e6-4c1c-b3c5-9b92b5c88fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = X_test_full.copy().set_index('unique_match_id', inplace=False)\n",
    "\n",
    "# missing value transformation\n",
    "transformed_test_data = missing_value_transformation_pipe.fit_transform(test_x)\n",
    "\n",
    "# feature scaling\n",
    "scaled_test_data = scale_numeric_data(transformed_test_data, categorical_columns = ['season', 'round', 'day', 'promoted', 'promoted_opponent', 'home'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38695bbc-1329-4600-baff-ef4c1559aaf9",
   "metadata": {},
   "source": [
    "#### Test Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841e25d5-71af-4de6-b9b0-f6c2725c54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucel\\Downloads\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# collect training target data\n",
    "test_y = y_test_full.copy().set_index('unique_match_id', inplace=False)\n",
    "\n",
    "# encode target variable (0, 1, 2)\n",
    "encoder = LabelEncoder()\n",
    "test_y_encoded = encoder.fit_transform(test_y)\n",
    "\n",
    "# Create a DataFrame with the encoded target variable and assign the index\n",
    "test_y_encoded = pd.DataFrame(test_y_encoded, index=test_y.index, columns=['target'])\n",
    "\n",
    "# keep only the index columns that are in the processed train X\n",
    "scaled_test_y = test_y_encoded[test_y_encoded.index.isin(scaled_test_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b45a19eb-4031-4e08-b0bd-f7d7169cb039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in local data file\n",
    "# Define the output directory\n",
    "output_dir = f\"{DATAPATH}/processed/\"\n",
    "\n",
    "# Save the train and test sets as CSV files\n",
    "scaled_training_data.to_csv(os.path.join(output_dir, 'X_train_full_processed.csv'), index=True)\n",
    "scaled_train_y.to_csv(os.path.join(output_dir, 'y_train_full_processed.csv'), index=True)\n",
    "scaled_test_data.to_csv(os.path.join(output_dir, 'X_test_full_processed.csv'), index=True)\n",
    "scaled_test_y.to_csv(os.path.join(output_dir, 'y_test_full_processed.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671ab33-5646-4b2b-93dc-2243e1354452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
